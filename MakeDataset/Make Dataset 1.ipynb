{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2c97ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import Literal, Tuple, Optional, Dict\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "YesNo = Literal[\"yes\", \"no\"]\n",
    "\n",
    "\n",
    "JUDGE_SYSTEM_PROMPT = \"\"\"You are a validation model designed for dataset quality control.\n",
    "\n",
    "Your task is to rigorously evaluate the reliability of a large language model (LLM) response by comparing the provided original information (raw) with the model-generated answer (answer).\n",
    "\n",
    "Follow these principles during evaluation:\n",
    "1. You will be given both the original information (raw) and the model output (answer).\n",
    "2. If the original information contains explicit facts, standard answers, or verifiable content, assess whether the answer is consistent with them.\n",
    "3. If the original information is extracted from literature or long-form text without a unique standard answer, focus on evaluating the logical soundness of the reasoning process in the answer.\n",
    "4. Identify any clear logical errors, hallucinations, unsupported claims, contradictions, or misinterpretations of the original information.\n",
    "5. If the answer is logically coherent and reasonably supported by the original information, it may be considered reliable even if the wording is not identical.\n",
    "\n",
    "You must output only a single JSON object and no additional text. The output format must be exactly:\n",
    "{\n",
    "  \"verdict\": \"yes\" or \"no\",\n",
    "  \"reason\": \"a brief explanation of the key reason for your judgment\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "JUDGE_USER_TEMPLATE = \"\"\"Please evaluate the following content.\n",
    "\n",
    "【Original Information (raw)】\n",
    "{raw}\n",
    "\n",
    "【Model Output (answer)】\n",
    "{answer}\n",
    "\n",
    "Determine whether the model output is reliable based on the original information.\n",
    "\n",
    "Return strictly a JSON object in the following format and do not include any additional text:\n",
    "{\n",
    "  \"verdict\": \"yes\" or \"no\",\n",
    "  \"reason\": \"one concise sentence explaining the reason for your decision\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def _extract_json_from_text(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Compatible with cases where the judge model occasionally adds explanations before or after the JSON:\n",
    "    Attempt to extract the content between the first `{` and the last `}` and parse it as JSON.\n",
    "    \"\"\"\n",
    "    text = (text or \"\").strip()\n",
    "    if not text:\n",
    "        raise ValueError(\"Empty judge response\")\n",
    "\n",
    "    # 直接尝试\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    # 截取大括号\n",
    "    l = text.find(\"{\")\n",
    "    r = text.rfind(\"}\")\n",
    "    if l != -1 and r != -1 and r > l:\n",
    "        candidate = text[l:r+1]\n",
    "        return json.loads(candidate)\n",
    "\n",
    "    raise ValueError(f\"Judge response is not valid JSON: {text[:200]}...\")\n",
    "\n",
    "\n",
    "def judge_answer_yesno(\n",
    "    client_check,\n",
    "    raw_info: str,\n",
    "    answer_content: str,\n",
    "    *,\n",
    "    judge_model: str,\n",
    "    temperature: float = 0.9,\n",
    "    max_retries: int = 3,\n",
    "    retry_sleep_sec: float = 1.5,\n",
    ") -> Tuple[YesNo, str, dict]:\n",
    "    \"\"\"\n",
    "    Invoke the new large model to make a judgment and return:\n",
    "    (verdict: 'yes'/'no', reason: str, full_json: dict)\n",
    "\n",
    "    - Built-in simple retry\n",
    "    \"\"\"\n",
    "    user_prompt = JUDGE_USER_TEMPLATE.format(raw=raw_info, answer=answer_content)\n",
    "\n",
    "    last_err: Optional[Exception] = None\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            resp = client_check.chat.completions.create(\n",
    "                model=judge_model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": JUDGE_SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "            )\n",
    "\n",
    "            text = resp.choices[0].message.content\n",
    "            obj = _extract_json_from_text(text)\n",
    "\n",
    "            verdict = str(obj.get(\"verdict\", \"\")).strip().lower()\n",
    "            reason = str(obj.get(\"reason\", \"\")).strip()\n",
    "\n",
    "            if verdict not in (\"yes\", \"no\"):\n",
    "                raise ValueError(f\"Invalid verdict: {verdict}\")\n",
    "\n",
    "            return verdict, reason, obj\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(retry_sleep_sec * attempt)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # On failure: conservatively return 'no' and include the error message to avoid interrupting the pipeline\n",
    "    return \"no\", f\"judge_failed: {last_err}\", {\"verdict\": \"no\", \"reason\": f\"judge_failed: {last_err}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f5e7351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_file(file_path):\n",
    "    \"\"\"\n",
    "    Read the specified JSON file and return the parsed object.\n",
    "    \n",
    "    :param file_path: Path to the JSON file\n",
    "    :return: Parsed JSON data (usually dict or list)\n",
    "    \"\"\"\n",
    "    # Use the with statement to open the file, ensuring it is properly closed afterwards\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Use the read() method to read all contents of the file into a string variable\n",
    "        data = file.read()\n",
    "    # print(type(data))\n",
    "    # At this point, the 'data' variable contains all the contents of the file.\n",
    "    # Note: If the file has multiple lines, 'data' will also include newline characters '\\n'.\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b18704db-9291-4412-b8a4-6d49ff0d8574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_txt_file(file_path, data):\n",
    "    \"\"\"\n",
    "    Write the given data to a JSON file at the specified path.\n",
    "    \n",
    "    :param file_path: Path to the JSON file\n",
    "    :param data: Data to be written (usually dict or list)\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20e45e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_check_json(checkdir: str, filename: str, verdict: YesNo) -> Dict[str, YesNo]:\n",
    "    os.makedirs(os.path.dirname(checkdir), exist_ok=True)\n",
    "\n",
    "    if os.path.exists(checkdir):\n",
    "        try:\n",
    "            with open(checkdir, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "        except Exception:\n",
    "            data = {}\n",
    "    else:\n",
    "        data = {}\n",
    "\n",
    "    data[filename] = verdict\n",
    "\n",
    "    with open(checkdir, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0a037ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_check_detail_json(\n",
    "    checkdir_detail: str,\n",
    "    filename: str,\n",
    "    verdict: YesNo,\n",
    "    reason: str,\n",
    "    judge_obj: dict,\n",
    "    *,\n",
    "    source_path: str = \"\",\n",
    "    txt_path: str = \"\",\n",
    "    raw_info: str = \"\",\n",
    "    answer_content: str = \"\",\n",
    "    preview_len: int = 30000,\n",
    "):\n",
    "    if os.path.exists(checkdir_detail):\n",
    "        try:\n",
    "            with open(checkdir_detail, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "        except Exception:\n",
    "            data = {}\n",
    "    else:\n",
    "        data = {}\n",
    "\n",
    "    data[filename] = {\n",
    "        \"verdict\": verdict,\n",
    "        \"reason\": reason,\n",
    "        \"judge\": judge_obj,\n",
    "        \"source_path\": source_path,\n",
    "        \"txt_path\": txt_path,\n",
    "        \"ts\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"raw_preview\": (raw_info[:preview_len] if raw_info else \"\"),\n",
    "        \"answer_preview\": (answer_content[:preview_len] if answer_content else \"\"),\n",
    "    }\n",
    "\n",
    "    os.makedirs(os.path.dirname(checkdir_detail), exist_ok=True)\n",
    "    with open(checkdir_detail, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cdd5bd-44c5-4822-a752-ba9f519673f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepseek_qa(txtfile, txtdir):\n",
    "    file_path = f\"{txtdir}\\\\{txtfile}\"\n",
    "    txt = read_txt_file(file_path)\n",
    "    print(f\"{txtfile} is running\")\n",
    "    \n",
    "    reasoning_content = \"\"  # define the complete reasoning process\n",
    "    answer_content = \"\"     # define the complete response\n",
    "    is_answering = False    # determine whether the reasoning has ended and the response has started\n",
    "\n",
    "    # create chat completion request\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"deepseek-v3\",  # using deepseek-v3 as an example, can be changed as needed\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"Please carefully read the provided paper and complete the following tasks:\n",
    "\n",
    "Scientific Problem and Answer:\n",
    "\n",
    "Extract the core scientific problem addressed in the paper and present it in the form of a question.\n",
    "\n",
    "Provide a detailed and comprehensive answer to the question based on the paper's content, including methods, experiments, results, and conclusions.\n",
    "\n",
    "Use <|begin_of_question|> and <|end_of_question|> to mark the start and end of the question.\n",
    "\n",
    "Use <|begin_of_answer|> and <|end_of_answer|> to mark the start and end of the answer.\n",
    "\n",
    "The answer should be written from an objective perspective, avoiding any reference to \"this paper\" or \"the authors.\"\n",
    "\n",
    "Thought Chain for Solving the Problem:\n",
    "\n",
    "Reconstruct the thought chain used to solve the scientific problem from an objective perspective or first-person perspective.\n",
    "\n",
    "Use <|begin_of_thought|> and <|end_of_thought|> to mark the start and end of the thought chain.\n",
    "\n",
    "The thought chain should include the following detailed elements:\n",
    "\n",
    "Problem Identification: Clearly state the problem or gap in the field that motivated the research.\n",
    "\n",
    "Why It Matters: Explain why solving this problem is important and what impact it could have on the field or real-world applications.\n",
    "\n",
    "Hypothesis Formation: Describe the hypothesis or key idea proposed to address the problem, and explain the reasoning behind it.\n",
    "\n",
    "Method Design: Explain the methodology or approach developed to test the hypothesis, including any novel techniques or tools. Clearly articulate why this method was chosen and how it addresses the problem.\n",
    "\n",
    "Experimental Setup: Detail the experimental design, including datasets, metrics, and baseline comparisons. Explain why these choices were made and how they align with the research goals.\n",
    "\n",
    "Data Analysis: Describe how the data was analyzed, including any challenges encountered and how they were addressed. Explain why specific analysis techniques were used and how they help validate the hypothesis.\n",
    "\n",
    "Results and Interpretation: Summarize the key results and their implications for the hypothesis and the broader field. Explain why these results are significant and how they contribute to solving the problem.\n",
    "\n",
    "Limitations and Future Work: Discuss the limitations of the approach and propose potential future directions for improvement or extension. Explain why these limitations exist and how future work could address them.\n",
    "\n",
    "Avoid any reference to \"this paper\" or \"the authors.\"\n",
    "\n",
    "Ensure the logic is clear and easy to understand, even for readers without deep expertise in the field.\n",
    "\n",
    "Thought Chain for Deriving the Research Idea:\n",
    "\n",
    "Reconstruct the thought chain that led to the formation of the research idea, from an objective perspective or first-person perspective.\n",
    "\n",
    "Use <|begin_of_idea_thought|> and <|end_of_idea_thought|> to mark the start and end of this thought chain.\n",
    "\n",
    "The thought chain should include the following detailed elements:\n",
    "\n",
    "Research Background: Describe the broader context of the research area and why it is important.\n",
    "\n",
    "Current State of the Field: Summarize the existing approaches and their limitations.\n",
    "\n",
    "Problem Discovery: Explain how the specific problem addressed in the paper was identified, including any observations or gaps in the literature.\n",
    "\n",
    "Idea Formation: Describe the process of developing the core idea or hypothesis, including any inspiration, analogies, or prior work that influenced the thinking.\n",
    "\n",
    "Validation of the Idea: Explain how the idea was initially validated or tested (e.g., through preliminary experiments, theoretical analysis, or literature review).\n",
    "\n",
    "Refinement of the Idea: Discuss how the idea evolved over time, including any adjustments or iterations based on feedback or new insights.\n",
    "\n",
    "Avoid any reference to \"this paper\" or \"the authors.\"\n",
    "\n",
    "Ensure the logic is clear and easy to understand, even for readers without deep expertise in the field.\n",
    "\n",
    "Output Format:\n",
    "\n",
    "<|begin_of_question|>\n",
    "[Present the core scientific problem in the form of a question]\n",
    "<|end_of_question|>\n",
    "\n",
    "<|begin_of_answer|>\n",
    "[Provide a detailed and comprehensive answer, including methods, experiments, results, and conclusions, written from an objective perspective]\n",
    "<|end_of_answer|>\n",
    "\n",
    "<|begin_of_thought|>\n",
    "[Describe the thought process in the first person or from an objective perspective, including all detailed elements: problem identification, why it matters, hypothesis formation, method design, experimental setup, data analysis, results and interpretation, limitations, and future work. Ensure the logic is clear and easy to understand.]\n",
    "<|end_of_thought|>\n",
    "\n",
    "<|begin_of_idea_thought|>\n",
    "[Describe the thought process in the first person or from an objective perspective, including all detailed elements: research background, current state of the field, problem discovery, idea formation, validation of the idea, and refinement of the idea. Ensure the logic is clear and easy to understand.]\n",
    "<|end_of_idea_thought|>\n",
    "\n",
    "Example:\n",
    "\n",
    "<|begin_of_question|>\n",
    "How can the generalization ability of deep learning models on small-sample datasets be improved without increasing computational complexity?\n",
    "<|end_of_question|>\n",
    "\n",
    "<|begin_of_answer|>\n",
    "A meta-learning-based adaptive weight adjustment method has been proposed to address this challenge. This method involves designing a lightweight meta-network that dynamically adjusts the weights of the main network based on the features of the input data. The core idea is to use meta-learning to simulate the model's performance across different tasks, thereby enhancing its generalization ability on small-sample data. Experiments conducted on several small-sample datasets, such as Mini-ImageNet and CIFAR-FS, demonstrated that this approach significantly improves model performance without substantially increasing computational complexity. For instance, on the Mini-ImageNet dataset, the model's accuracy improved by approximately 8%. However, the method's sensitivity to hyperparameters was identified as a limitation, suggesting a need for further optimization, such as exploring more efficient meta-network architectures.\n",
    "<|end_of_answer|>\n",
    "\n",
    "<|begin_of_thought|>\n",
    "The problem of poor generalization in deep learning models on small-sample datasets was identified as a significant challenge in the field. Existing models often overfit due to limited data availability, leading to suboptimal performance in real-world applications. Solving this problem is crucial because many practical scenarios, such as medical diagnosis or rare event prediction, involve limited data. Improving generalization in such settings could enable more reliable and accurate AI systems.\n",
    "\n",
    "To address this issue, a hypothesis was formed: dynamically adjusting model parameters based on input data features could improve adaptability and generalization without requiring additional computational resources. This idea was motivated by the observation that traditional models use fixed parameters, which may not be optimal for diverse small-sample tasks. By allowing the model to adapt its parameters dynamically, it could better capture the unique characteristics of each task.\n",
    "\n",
    "To test this hypothesis, a lightweight meta-network was designed. This meta-network operates alongside the main model, analyzing input data features and dynamically adjusting the main model's weights. The design prioritized efficiency to ensure that the computational overhead remained minimal. The meta-network was trained using a meta-learning framework, which allowed it to simulate performance across diverse tasks and datasets. This approach was chosen because meta-learning has shown promise in enabling models to generalize across tasks, making it a natural fit for small-sample problems.\n",
    "\n",
    "Experiments were conducted on multiple small-sample datasets, including Mini-ImageNet and CIFAR-FS. These datasets were selected because they are widely used benchmarks for small-sample learning, allowing for fair comparisons with existing methods. The experimental setup included comparisons with baseline models to evaluate performance improvements. Key metrics such as accuracy, training time, and computational cost were measured. These metrics were chosen because they directly reflect the goals of improving generalization without increasing computational complexity.\n",
    "\n",
    "During data analysis, it was observed that the method's performance was highly dependent on the choice of hyperparameters. This sensitivity was addressed through extensive hyperparameter tuning, but it remains a limitation of the approach. Additionally, the method's effectiveness varied across different types of small-sample datasets, suggesting that further customization may be needed for specific applications. These challenges were analyzed to understand their root causes and identify potential solutions.\n",
    "\n",
    "The results showed that the proposed method significantly improved model performance, particularly in data-scarce scenarios. For example, on the Mini-ImageNet dataset, accuracy improved by approximately 8%, while computational costs remained comparable to baseline models. These results are significant because they demonstrate that dynamic weight adjustment can effectively enhance generalization without sacrificing efficiency. This finding has broad implications for fields where data is scarce, such as healthcare or environmental monitoring.\n",
    "\n",
    "However, the method's sensitivity to hyperparameters and dataset variability highlights the need for further refinement. Future work could explore more robust meta-network architectures, automated hyperparameter optimization techniques, and applications to a broader range of tasks, such as medical imaging or natural language processing. These directions are important because they address the current limitations and could further improve the method's practicality and effectiveness.\n",
    "<|end_of_thought|>\n",
    "\n",
    "<|begin_of_idea_thought|>\n",
    "The research idea emerged from a broader interest in improving the practicality of deep learning models in real-world scenarios, where data is often limited. The field of small-sample learning has gained attention due to its relevance in applications like medical imaging, where collecting large datasets is expensive or ethically challenging. However, existing methods often struggle with overfitting and fail to generalize well to new tasks.\n",
    "\n",
    "A review of the current state of the field revealed that most approaches focus on either data augmentation or complex model architectures, which often come with high computational costs. While these methods can improve performance, they are not always feasible in resource-constrained settings. This gap highlighted the need for a more efficient solution that could enhance generalization without increasing computational complexity.\n",
    "\n",
    "The specific problem of poor generalization in small-sample datasets was identified through experiments with existing models. It became clear that fixed model parameters, which work well in large-scale settings, are not suitable for small-sample tasks where data variability is high. This observation led to the hypothesis that dynamic parameter adjustment could be a key to improving generalization.\n",
    "\n",
    "The core idea of using meta-learning for dynamic weight adjustment was inspired by prior work in few-shot learning, where meta-learning has been successful in enabling models to adapt quickly to new tasks. The analogy was drawn that a similar approach could be applied to small-sample learning, but with a focus on efficiency to avoid excessive computational overhead.\n",
    "\n",
    "To validate this idea, preliminary experiments were conducted using simple meta-network prototypes. These experiments showed promising results, indicating that dynamic weight adjustment could indeed improve generalization. However, they also revealed challenges, such as the meta-network's sensitivity to hyperparameters, which needed to be addressed.\n",
    "\n",
    "Over time, the idea was refined through iterative experimentation and feedback from the research community. The meta-network architecture was optimized for efficiency, and new training techniques were introduced to stabilize performance. These refinements were crucial in transforming the initial idea into a practical and effective solution.\n",
    "<|end_of_idea_thought|>\n",
    "\n",
    "There is Artical:\n",
    "{txt}\"\"\"}\n",
    "        ],\n",
    "        stream=True\n",
    "        # Uncomment the following to include token usage in the final chunk\n",
    "        # stream_options={\n",
    "        #     \"include_usage\": True\n",
    "        # }\n",
    "    )\n",
    "\n",
    "    for chunk in stream:\n",
    "        # Handle usage information\n",
    "        if not getattr(chunk, 'choices', None):\n",
    "            print(\"\\n\" + \"=\" * 20 + \"Token Usage\" + \"=\" * 20 + \"\\n\")\n",
    "            print(chunk.usage)\n",
    "            continue\n",
    "\n",
    "        delta = chunk.choices[0].delta\n",
    "\n",
    "        # Handle response content\n",
    "        if getattr(delta, 'content', None):\n",
    "            # print(delta.content, end='', flush=True)\n",
    "            answer_content += delta.content\n",
    "\n",
    "    # If you need to print the full content, uncomment the following\n",
    "\n",
    "    # print(\"=\" * 20 + \"Complete Response\" + \"=\" * 20 + \"\\n\")\n",
    "    # print(answer_content)\n",
    "\n",
    "    write_txt_file(file_path, answer_content)\n",
    "    print(answer_content)\n",
    "    print(\"+++++++++++++++++++\")\n",
    "    print(txt)\n",
    "    verdict, reason, judge_obj = judge_answer_yesno(\n",
    "        client_check,\n",
    "        raw_info=txt,\n",
    "        answer_content=answer_content,\n",
    "        judge_model=\"ModelName\",   # Replace with your reviewer model name\n",
    "\n",
    "    )\n",
    "\n",
    "    # Summary: filename -> yes/no\n",
    "    update_check_json(checkdir, os.path.basename(file_path), verdict)\n",
    "\n",
    "    # Details: filename -> verdict / reason / original judge JSON\n",
    "    update_check_detail_json(\n",
    "        checkdir_detail,\n",
    "        os.path.basename(file_path),\n",
    "        verdict,\n",
    "        reason,\n",
    "        judge_obj,\n",
    "        source_path=file_path,              \n",
    "        txt_path=file_path,                 \n",
    "        raw_info=txt,\n",
    "        answer_content=answer_content,\n",
    "    )\n",
    "    return f\"{txtfile} is done\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19a81f94-b6b4-4712-96a2-5523a8736f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(txtdir):\n",
    "    futures = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        for txtfile in os.listdir(txtdir):\n",
    "            if txtfile.endswith('.txt'):  # ensure only text files are processed\n",
    "                future = executor.submit(deepseek_qa, txtfile, txtdir)\n",
    "                futures.append(future)\n",
    "        \n",
    "        # collect results\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                print(result)\n",
    "            except Exception as e:\n",
    "                print(f\"An exception occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf524a27-a871-4302-8249-9b6aead4f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "client = OpenAI(\n",
    "    # If the environment variable is not configured, replace the following line with your Bailian API Key, e.g., api_key=\"sk-xxx\",\n",
    "    api_key=\"\",  # How to get an API Key: https://help.aliyun.com/zh/model-studio/developer-reference/get-api-key\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "client_check = OpenAI(\n",
    "    # If the environment variable is not configured, replace the following line with your Bailian API Key, e.g., api_key=\"sk-xxx\",\n",
    "    api_key=\"\",  # How to get an API Key: https://help.aliyun.com/zh/model-studio/developer-reference/get-api-key\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "txtdir = \"F:\\\\Working\\\\ModelDistillation\\\\DDrevise\\\\test2\"\n",
    "checkdir = \"F:\\\\Working\\\\ModelDistillation\\\\\\\\DDrevise\\\\test2\\\\check.json\"\n",
    "checkdir_detail = r\"F:\\Working\\ModelDistillation\\DDrevise\\test2\\\\check_detail.json\"\n",
    "\n",
    "main(txtdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd8e322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
